#!/usr/bin/env python3
"""
ML Modeling & Predictive Analysis
–§–∞–∑–∞ 3: Machine Learning –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è –¥–ª—è prediction outcome-based –º–µ—Ç—Ä–∏–∫

–ú–∞–≥—ñ—Å—Ç–µ—Ä—Å—å–∫–∞ —Ä–æ–±–æ—Ç–∞: Outcome-based –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ TypeScript –∫–æ–¥—É
–ê–≤—Ç–æ—Ä: –°–ª–∞–±–µ–Ω–∫–æ –ö–æ—Å—Ç—è–Ω—Ç–∏–Ω –û–ª–µ–≥–æ–≤–∏—á
–ì—Ä—É–ø–∞: –ê–°-202
–û–¥–µ—Å—å–∫–∏–π –ø–æ–ª—ñ—Ç–µ—Ö–Ω—ñ—á–Ω–∏–π –Ω–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç
"""

import warnings
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import (
    r2_score,
    mean_squared_error,
    mean_absolute_error,
)
import xgboost as xgb
import lightgbm as lgb
import shap

warnings.filterwarnings("ignore")

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
plt.style.use("seaborn-v0_8-darkgrid")
sns.set_palette("husl")
plt.rcParams["figure.dpi"] = 300
plt.rcParams["savefig.dpi"] = 300
plt.rcParams["figure.figsize"] = (12, 8)

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
REPORTS_DIR = Path("../reports")
ML_DIR = REPORTS_DIR / "ml"
ML_DIR.mkdir(exist_ok=True)

print("=" * 80)
print("ML MODELING & PREDICTIVE ANALYSIS")
print("–§–∞–∑–∞ 3: Machine Learning –¥–ª—è prediction outcome-based –º–µ—Ç—Ä–∏–∫")
print("=" * 80)
print()


# ============================================================================
# 1. DATA LOADING & PREPROCESSING
# ============================================================================
print("=" * 80)
print("1. DATA LOADING & PREPROCESSING")
print("=" * 80)

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è engineered features
df = pd.read_csv(REPORTS_DIR / "statistical" / "engineered_features.csv")
print(
    f"‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ engineered features: {df.shape[0]} –ø—Ä–æ–µ–∫—Ç—ñ–≤ √ó {df.shape[1]} features"
)

# –í–∏–¥–∞–ª–∏—Ç–∏ –∫–æ–ª–æ–Ω–∫—É name (–Ω–µ feature)
if "name" in df.columns:
    project_names = df["name"].copy()
    df = df.drop("name", axis=1)
else:
    project_names = None

# –í–∏–¥–∞–ª–∏—Ç–∏ non-numeric –∫–æ–ª–æ–Ω–∫–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ collectedAt)
non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
if non_numeric_cols:
    print(f"‚úì –í–∏–¥–∞–ª–µ–Ω–æ {len(non_numeric_cols)} non-numeric –∫–æ–ª–æ–Ω–æ–∫: {non_numeric_cols}")
    df = df.select_dtypes(include=[np.number])

print(f"‚úì Features –ø—ñ—Å–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è name —Ç–∞ non-numeric: {df.shape[1]}")


# ============================================================================
# 2. FEATURE SELECTION
# ============================================================================
print()
print("=" * 80)
print("2. FEATURE SELECTION")
print("=" * 80)

# Target variables
TARGET_VARS = ["overallScore", "bi_timeToMarket", "bi_communityGrowth"]

# –í–∏–¥–∞–ª–∏—Ç–∏ target variables –∑ features
feature_cols = [col for col in df.columns if col not in TARGET_VARS]
print(f"‚úì –ü–æ—á–∞—Ç–∫–æ–≤–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å features: {len(feature_cols)}")

# Safeguard: –≤–∏—è–≤–∏—Ç–∏ leaked features (transformations of targets)
print("\nüîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ leaked features...")
TARGET_PATTERNS = ["timeToMarket", "communityGrowth", "overallScore"]
leaked_features = []

for col in feature_cols:
    for pattern in TARGET_PATTERNS:
        if pattern in col and col not in TARGET_VARS:
            leaked_features.append(col)
            break

if leaked_features:
    print(f"‚ö†Ô∏è  WARNING: –í–∏—è–≤–ª–µ–Ω–æ {len(leaked_features)} potential leaked features:")
    for feat in leaked_features:
        print(f"   - {feat}")

    # –í–∏–¥–∞–ª–∏—Ç–∏ leaked features
    feature_cols = [col for col in feature_cols if col not in leaked_features]
    print(f"‚úì –í–∏–¥–∞–ª–µ–Ω–æ leaked features, –∑–∞–ª–∏—à–∏–ª–æ—Å—å: {len(feature_cols)} features")
else:
    print("‚úì Leaked features –ù–ï –≤–∏—è–≤–ª–µ–Ω–æ")
print()

# –í–∏–¥–∞–ª–∏—Ç–∏ highly correlated features (correlation > 0.95)
corr_matrix = df[feature_cols].corr().abs()
upper_triangle = corr_matrix.where(
    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
)
to_drop = [
    column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)
]

print(f"‚úì –í–∏–¥–∞–ª–µ–Ω–æ {len(to_drop)} highly correlated features (r > 0.95)")
feature_cols = [col for col in feature_cols if col not in to_drop]

# –í–∏–¥–∞–ª–∏—Ç–∏ scaled duplicates - –∑–∞–ª–∏—à–∏—Ç–∏ —Ç—ñ–ª—å–∫–∏ original –≤–µ—Ä—Å—ñ—ó
# (–≤–∏–¥–∞–ª–∏—Ç–∏ _std —Ç–∞ _norm —Å—É—Ñ—ñ–∫—Å–∏)
original_features = []
scaled_features = {"std": [], "norm": []}

for col in feature_cols:
    if col.endswith("_std"):
        scaled_features["std"].append(col)
    elif col.endswith("_norm"):
        scaled_features["norm"].append(col)
    else:
        original_features.append(col)

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î original –≤–µ—Ä—Å—ñ—è –¥–ª—è –∫–æ–∂–Ω–æ—ó scaled
features_to_keep = original_features.copy()
for std_col in scaled_features["std"]:
    base_name = std_col[:-4]  # –≤–∏–¥–∞–ª–∏—Ç–∏ _std
    if base_name not in original_features:
        features_to_keep.append(std_col)  # –∑–∞–ª–∏—à–∏—Ç–∏ —è–∫—â–æ –Ω–µ–º–∞—î original

for norm_col in scaled_features["norm"]:
    base_name = norm_col[:-5]  # –≤–∏–¥–∞–ª–∏—Ç–∏ _norm
    if (
        base_name not in original_features
        and base_name + "_std" not in features_to_keep
    ):
        features_to_keep.append(norm_col)  # –∑–∞–ª–∏—à–∏—Ç–∏ —è–∫—â–æ –Ω–µ–º–∞—î –Ω—ñ original –Ω—ñ std

feature_cols = features_to_keep
print(f"‚úì –ü—ñ—Å–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è scaled duplicates: {len(feature_cols)} features")

# –°—Ç–≤–æ—Ä–∏—Ç–∏ final dataset
X = df[feature_cols].copy()
y_overall = df["overallScore"].copy()
y_time_to_market = df["bi_timeToMarket"].copy()
y_community = df["bi_communityGrowth"].copy()

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è selected features
selected_features_df = pd.DataFrame({"Feature": feature_cols})
selected_features_df.to_csv(ML_DIR / "selected_features.csv", index=False)
print(f"‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ selected features: {len(feature_cols)} features")
print()


# ============================================================================
# 3. TRAIN/TEST SPLIT
# ============================================================================
print("=" * 80)
print("3. TRAIN/TEST SPLIT")
print("=" * 80)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ 70/15/15 split
test_size = 0.15
val_size = 0.15 / (1 - test_size)  # 15% –≤—ñ–¥ —Ä–µ—à—Ç–∏ –ø—ñ—Å–ª—è test split

random_state = 42

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è splits –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ target
splits = {}

for target_name, y in [
    ("overallScore", y_overall),
    ("timeToMarket", y_time_to_market),
    ("communityGrowth", y_community),
]:
    # Test split
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    # Validation split
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=val_size, random_state=random_state
    )

    splits[target_name] = {
        "X_train": X_train,
        "X_val": X_val,
        "X_test": X_test,
        "y_train": y_train,
        "y_val": y_val,
        "y_test": y_test,
    }

    print(
        f"‚úì {target_name}: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}"
    )

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è split info
split_info = pd.DataFrame(
    {
        "Target": ["overallScore", "timeToMarket", "communityGrowth"],
        "Train Size": [
            len(splits["overallScore"]["X_train"]),
            len(splits["timeToMarket"]["X_train"]),
            len(splits["communityGrowth"]["X_train"]),
        ],
        "Val Size": [
            len(splits["overallScore"]["X_val"]),
            len(splits["timeToMarket"]["X_val"]),
            len(splits["communityGrowth"]["X_val"]),
        ],
        "Test Size": [
            len(splits["overallScore"]["X_test"]),
            len(splits["timeToMarket"]["X_test"]),
            len(splits["communityGrowth"]["X_test"]),
        ],
    }
)
split_info.to_csv(ML_DIR / "train_test_split.csv", index=False)
print("‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ split info")
print()


# ============================================================================
# 4. MODEL TRAINING & EVALUATION
# ============================================================================
print("=" * 80)
print("4. MODEL TRAINING & EVALUATION")
print("=" * 80)

# –ú–æ–¥–µ–ª—ñ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
models = {
    "Linear Regression": LinearRegression(),
    "Ridge": Ridge(alpha=1.0, random_state=random_state),
    "Lasso": Lasso(alpha=0.1, random_state=random_state),
    "ElasticNet": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=random_state),
    "Random Forest": RandomForestRegressor(
        n_estimators=100, max_depth=10, random_state=random_state, n_jobs=-1
    ),
    "XGBoost": xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=random_state,
        n_jobs=-1,
    ),
    "LightGBM": lgb.LGBMRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=random_state,
        n_jobs=-1,
        verbose=-1,
    ),
}

# –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –≤—Å—ñ—Ö –º–æ–¥–µ–ª–µ–π
all_results = []

# –î–ª—è –∫–æ–∂–Ω–æ–≥–æ target
for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    print(f"\n{'=' * 60}")
    print(f"TARGET: {target_name}")
    print(f"{'=' * 60}")

    split = splits[target_name]

    # Scaling features –¥–ª—è neural network based models
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(split["X_train"])
    X_val_scaled = scaler.transform(split["X_val"])
    X_test_scaled = scaler.transform(split["X_test"])

    # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ
    for model_name, model in models.items():
        print(f"\n  Training {model_name}...")

        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ scaled features –¥–ª—è –º–æ–¥–µ–ª–µ–π —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å scaling
        if model_name in ["Ridge", "Lasso", "ElasticNet"]:
            X_tr = X_train_scaled
            X_v = X_val_scaled
            X_te = X_test_scaled
        else:
            X_tr = split["X_train"]
            X_v = split["X_val"]
            X_te = split["X_test"]

        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
        model.fit(X_tr, split["y_train"])

        # Predictions
        y_train_pred = model.predict(X_tr)
        y_val_pred = model.predict(X_v)
        y_test_pred = model.predict(X_te)

        # Metrics
        train_r2 = r2_score(split["y_train"], y_train_pred)
        val_r2 = r2_score(split["y_val"], y_val_pred)
        test_r2 = r2_score(split["y_test"], y_test_pred)

        train_rmse = np.sqrt(mean_squared_error(split["y_train"], y_train_pred))
        val_rmse = np.sqrt(mean_squared_error(split["y_val"], y_val_pred))
        test_rmse = np.sqrt(mean_squared_error(split["y_test"], y_test_pred))

        train_mae = mean_absolute_error(split["y_train"], y_train_pred)
        val_mae = mean_absolute_error(split["y_val"], y_val_pred)
        test_mae = mean_absolute_error(split["y_test"], y_test_pred)

        print(
            f"    Train R¬≤: {train_r2:.4f}, Val R¬≤: {val_r2:.4f}, Test R¬≤: {test_r2:.4f}"
        )
        print(f"    Test RMSE: {test_rmse:.4f}, Test MAE: {test_mae:.4f}")

        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        all_results.append(
            {
                "Target": target_name,
                "Model": model_name,
                "Train R¬≤": train_r2,
                "Val R¬≤": val_r2,
                "Test R¬≤": test_r2,
                "Train RMSE": train_rmse,
                "Val RMSE": val_rmse,
                "Test RMSE": test_rmse,
                "Train MAE": train_mae,
                "Val MAE": val_mae,
                "Test MAE": test_mae,
            }
        )

# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è results
results_df = pd.DataFrame(all_results)
results_df.to_csv(ML_DIR / "model_performance.csv", index=False)
print("\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ model performance results")
print()


# ============================================================================
# 5. CROSS-VALIDATION
# ============================================================================
print("=" * 80)
print("5. CROSS-VALIDATION (5-Fold)")
print("=" * 80)

cv_results = []

for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    print(f"\nTarget: {target_name}")

    split = splits[target_name]
    X_full = pd.concat([split["X_train"], split["X_val"]])
    y_full = pd.concat([split["y_train"], split["y_val"]])

    kfold = KFold(n_splits=5, shuffle=True, random_state=random_state)

    for model_name, model in models.items():
        # Cross-validation
        cv_scores = cross_val_score(
            model, X_full, y_full, cv=kfold, scoring="r2", n_jobs=-1
        )

        print(f"  {model_name}: Œº={cv_scores.mean():.4f}, œÉ={cv_scores.std():.4f}")

        cv_results.append(
            {
                "Target": target_name,
                "Model": model_name,
                "CV Mean R¬≤": cv_scores.mean(),
                "CV Std R¬≤": cv_scores.std(),
                "Fold 1": cv_scores[0],
                "Fold 2": cv_scores[1],
                "Fold 3": cv_scores[2],
                "Fold 4": cv_scores[3],
                "Fold 5": cv_scores[4],
            }
        )

cv_df = pd.DataFrame(cv_results)
cv_df.to_csv(ML_DIR / "cv_scores.csv", index=False)
print("\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ cross-validation results")
print()


# ============================================================================
# 6. FEATURE IMPORTANCE ANALYSIS
# ============================================================================
print("=" * 80)
print("6. FEATURE IMPORTANCE ANALYSIS")
print("=" * 80)

# –î–ª—è –∫–æ–∂–Ω–æ–≥–æ target - Random Forest —Ç–∞ XGBoost importance
for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    print(f"\nTarget: {target_name}")

    split = splits[target_name]

    # Random Forest
    rf_model = RandomForestRegressor(
        n_estimators=100, max_depth=10, random_state=random_state, n_jobs=-1
    )
    rf_model.fit(split["X_train"], split["y_train"])

    rf_importance = pd.DataFrame(
        {
            "Feature": feature_cols,
            "Importance": rf_model.feature_importances_,
        }
    )
    rf_importance = rf_importance.sort_values("Importance", ascending=False)
    rf_importance.to_csv(
        ML_DIR / f"feature_importance_rf_{target_name}.csv", index=False
    )

    print("  ‚úì Random Forest top-5 features:")
    for idx, row in rf_importance.head(5).iterrows():
        print(f"    {row['Feature']}: {row['Importance']:.4f}")

    # XGBoost
    xgb_model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=random_state,
        n_jobs=-1,
    )
    xgb_model.fit(split["X_train"], split["y_train"])

    xgb_importance = pd.DataFrame(
        {
            "Feature": feature_cols,
            "Importance": xgb_model.feature_importances_,
        }
    )
    xgb_importance = xgb_importance.sort_values("Importance", ascending=False)
    xgb_importance.to_csv(
        ML_DIR / f"feature_importance_xgb_{target_name}.csv", index=False
    )

    print("  ‚úì XGBoost top-5 features:")
    for idx, row in xgb_importance.head(5).iterrows():
        print(f"    {row['Feature']}: {row['Importance']:.4f}")

print("\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ feature importance results")
print()


# ============================================================================
# 7. SHAP ANALYSIS (–¥–ª—è –Ω–∞–π–∫—Ä–∞—â–æ—ó –º–æ–¥–µ–ª—ñ - XGBoost)
# ============================================================================
print("=" * 80)
print("7. SHAP ANALYSIS (Model Explainability)")
print("=" * 80)

shap_results = {}

for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    print(f"\nTarget: {target_name}")

    split = splits[target_name]

    # –¢—Ä–µ–Ω—É—î–º–æ XGBoost –º–æ–¥–µ–ª—å
    xgb_model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=random_state,
        n_jobs=-1,
    )
    xgb_model.fit(split["X_train"], split["y_train"])

    # SHAP explainer
    print("  Computing SHAP values...")
    explainer = shap.TreeExplainer(xgb_model)
    shap_values = explainer.shap_values(split["X_test"])

    # –°–µ—Ä–µ–¥–Ω—ñ |SHAP values| –¥–ª—è –∫–æ–∂–Ω–æ—ó feature
    mean_abs_shap = np.abs(shap_values).mean(axis=0)
    shap_importance = pd.DataFrame(
        {"Feature": feature_cols, "Mean |SHAP|": mean_abs_shap}
    )
    shap_importance = shap_importance.sort_values("Mean |SHAP|", ascending=False)
    shap_importance.to_csv(ML_DIR / f"shap_importance_{target_name}.csv", index=False)

    print("  ‚úì Top-5 important features (by SHAP):")
    for idx, row in shap_importance.head(5).iterrows():
        print(f"    {row['Feature']}: {row['Mean |SHAP|']:.4f}")

    shap_results[target_name] = {
        "explainer": explainer,
        "shap_values": shap_values,
        "X_test": split["X_test"],
    }

print("\n‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ SHAP analysis results")
print()


# ============================================================================
# 8. PREDICTIONS COMPARISON
# ============================================================================
print("=" * 80)
print("8. PREDICTIONS COMPARISON (Best Model - XGBoost)")
print("=" * 80)

predictions_data = []

for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    split = splits[target_name]

    # XGBoost predictions
    xgb_model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=random_state,
        n_jobs=-1,
    )
    xgb_model.fit(split["X_train"], split["y_train"])
    predictions = xgb_model.predict(split["X_test"])

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ test project
    for i, (actual, pred) in enumerate(zip(split["y_test"], predictions)):
        predictions_data.append(
            {
                "Target": target_name,
                "Project Index": split["X_test"].index[i],
                "Actual": actual,
                "Predicted": pred,
                "Error": pred - actual,
                "Abs Error": abs(pred - actual),
                "Squared Error": (pred - actual) ** 2,
            }
        )

predictions_df = pd.DataFrame(predictions_data)
predictions_df.to_csv(ML_DIR / "predictions_comparison.csv", index=False)
print("‚úì –ó–±–µ—Ä–µ–∂–µ–Ω–æ predictions comparison")
print()


# ============================================================================
# 9. VISUALIZATIONS
# ============================================================================
print("=" * 80)
print("9. GENERATING VISUALIZATIONS")
print("=" * 80)

# 9.1. Feature Selection Correlation Heatmap
print("\n9.1. Feature selection correlation heatmap...")
fig, ax = plt.subplots(figsize=(14, 12))

# –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ —Ç–æ–ø-30 features –∑–∞ correlation –∑ overallScore
feature_importance_overall = pd.read_csv(
    ML_DIR / "feature_importance_xgb_overallScore.csv"
)
top_features = feature_importance_overall.head(30)["Feature"].tolist()

if len(top_features) > 0:
    corr_top = df[top_features].corr()
    sns.heatmap(
        corr_top,
        annot=False,
        cmap="coolwarm",
        center=0,
        square=True,
        linewidths=0.5,
        cbar_kws={"shrink": 0.8},
        ax=ax,
    )
    ax.set_title(
        "Correlation Matrix: Top-30 Most Important Features", fontsize=14, pad=15
    )
    plt.tight_layout()
    plt.savefig(ML_DIR / "13_feature_selection.png", dpi=300, bbox_inches="tight")
    plt.close()
    print("  ‚úì Saved: 13_feature_selection.png")


# 9.2. Model Comparison Bar Chart
print("\n9.2. Model comparison bar chart...")
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    target_results = results_df[results_df["Target"] == target_name]

    axes[idx].barh(
        target_results["Model"], target_results["Test R¬≤"], color="steelblue"
    )
    axes[idx].set_xlabel("Test R¬≤")
    axes[idx].set_title(f"Model Performance: {target_name}")
    axes[idx].grid(True, alpha=0.3, axis="x")
    axes[idx].axvline(x=0.75, color="red", linestyle="--", label="Target (0.75)")
    axes[idx].legend()

plt.tight_layout()
plt.savefig(ML_DIR / "14_model_comparison.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 14_model_comparison.png")


# 9.3. Learning Curves (Train vs Val R¬≤)
print("\n9.3. Learning curves...")
fig, axes = plt.subplots(3, 3, figsize=(18, 15))
axes = axes.flatten()

plot_idx = 0
for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    target_results = results_df[results_df["Target"] == target_name]

    for idx, model_name in enumerate(["Random Forest", "XGBoost", "LightGBM"]):
        model_data = target_results[target_results["Model"] == model_name]

        if len(model_data) > 0:
            train_r2 = model_data["Train R¬≤"].values[0]
            val_r2 = model_data["Val R¬≤"].values[0]
            test_r2 = model_data["Test R¬≤"].values[0]

            axes[plot_idx].bar(
                ["Train", "Val", "Test"],
                [train_r2, val_r2, test_r2],
                color=["blue", "orange", "green"],
                alpha=0.7,
            )
            axes[plot_idx].set_ylabel("R¬≤")
            axes[plot_idx].set_title(f"{model_name} - {target_name}")
            axes[plot_idx].set_ylim([0, 1])
            axes[plot_idx].grid(True, alpha=0.3, axis="y")

        plot_idx += 1

plt.tight_layout()
plt.savefig(ML_DIR / "15_learning_curves.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 15_learning_curves.png")


# 9.4. Residual Plots (Best Model - XGBoost)
print("\n9.4. Residual plots...")
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    pred_data = predictions_df[predictions_df["Target"] == target_name]

    axes[idx].scatter(pred_data["Predicted"], pred_data["Error"], alpha=0.6)
    axes[idx].axhline(y=0, color="red", linestyle="--")
    axes[idx].set_xlabel("Predicted Value")
    axes[idx].set_ylabel("Residual (Error)")
    axes[idx].set_title(f"Residual Plot: {target_name}")
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(ML_DIR / "16_residual_plots.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 16_residual_plots.png")


# 9.5. Feature Importance Comparison
print("\n9.5. Feature importance comparison...")
fig, axes = plt.subplots(3, 1, figsize=(12, 15))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    rf_imp = pd.read_csv(ML_DIR / f"feature_importance_rf_{target_name}.csv")
    xgb_imp = pd.read_csv(ML_DIR / f"feature_importance_xgb_{target_name}.csv")

    # –¢–æ–ø-10 features
    top_features = xgb_imp.head(10)["Feature"].tolist()

    rf_values = [
        rf_imp[rf_imp["Feature"] == f]["Importance"].values[0]
        if f in rf_imp["Feature"].values
        else 0
        for f in top_features
    ]
    xgb_values = [
        xgb_imp[xgb_imp["Feature"] == f]["Importance"].values[0]
        if f in xgb_imp["Feature"].values
        else 0
        for f in top_features
    ]

    x = np.arange(len(top_features))
    width = 0.35

    axes[idx].barh(x - width / 2, rf_values, width, label="Random Forest", alpha=0.8)
    axes[idx].barh(x + width / 2, xgb_values, width, label="XGBoost", alpha=0.8)
    axes[idx].set_yticks(x)
    axes[idx].set_yticklabels(top_features, fontsize=9)
    axes[idx].set_xlabel("Importance")
    axes[idx].set_title(f"Feature Importance: {target_name}")
    axes[idx].legend()
    axes[idx].grid(True, alpha=0.3, axis="x")

plt.tight_layout()
plt.savefig(
    ML_DIR / "17_feature_importance_comparison.png", dpi=300, bbox_inches="tight"
)
plt.close()
print("  ‚úì Saved: 17_feature_importance_comparison.png")


# 9.6. Predictions vs Actual Scatter Plots
print("\n9.6. Predictions vs actual scatter plots...")
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    pred_data = predictions_df[predictions_df["Target"] == target_name]

    axes[idx].scatter(
        pred_data["Actual"], pred_data["Predicted"], alpha=0.6, s=80, edgecolors="black"
    )

    # Perfect prediction line
    min_val = min(pred_data["Actual"].min(), pred_data["Predicted"].min())
    max_val = max(pred_data["Actual"].max(), pred_data["Predicted"].max())
    axes[idx].plot([min_val, max_val], [min_val, max_val], "r--", lw=2)

    axes[idx].set_xlabel("Actual Value")
    axes[idx].set_ylabel("Predicted Value")
    axes[idx].set_title(f"Predictions vs Actual: {target_name}")
    axes[idx].grid(True, alpha=0.3)

    # R¬≤ on plot
    target_r2 = results_df[
        (results_df["Target"] == target_name) & (results_df["Model"] == "XGBoost")
    ]["Test R¬≤"].values[0]
    axes[idx].text(
        0.05,
        0.95,
        f"R¬≤ = {target_r2:.4f}",
        transform=axes[idx].transAxes,
        fontsize=12,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="white", alpha=0.8),
    )

plt.tight_layout()
plt.savefig(ML_DIR / "18_predictions_vs_actual.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 18_predictions_vs_actual.png")


# 9.7. SHAP Summary Plots
print("\n9.7. SHAP summary plots...")
fig, axes = plt.subplots(3, 1, figsize=(12, 18))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    shap_data = shap_results[target_name]

    plt.sca(axes[idx])
    shap.summary_plot(
        shap_data["shap_values"],
        shap_data["X_test"],
        plot_type="bar",
        max_display=15,
        show=False,
    )
    axes[idx].set_title(f"SHAP Feature Importance: {target_name}", fontsize=12)

plt.tight_layout()
plt.savefig(ML_DIR / "19_shap_summary.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 19_shap_summary.png")


# 9.8. SHAP Dependence Plots (Top-3 features)
print("\n9.8. SHAP dependence plots...")

for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    shap_imp = pd.read_csv(ML_DIR / f"shap_importance_{target_name}.csv")
    top_3_features = shap_imp.head(3)["Feature"].tolist()

    if len(top_3_features) >= 3:
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        shap_data = shap_results[target_name]

        for i, feature in enumerate(top_3_features):
            if feature in shap_data["X_test"].columns:
                feature_idx = shap_data["X_test"].columns.tolist().index(feature)
                plt.sca(axes[i])
                shap.dependence_plot(
                    feature_idx,
                    shap_data["shap_values"],
                    shap_data["X_test"],
                    show=False,
                )
                axes[i].set_title(f"{feature}", fontsize=10)

        plt.tight_layout()
        plt.savefig(
            ML_DIR / f"20_shap_dependence_{target_name}.png",
            dpi=300,
            bbox_inches="tight",
        )
        plt.close()
        print(f"  ‚úì Saved: 20_shap_dependence_{target_name}.png")


# 9.9. Cross-Validation Scores Distribution
print("\n9.9. Cross-validation scores distribution...")
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for idx, target_name in enumerate(["overallScore", "timeToMarket", "communityGrowth"]):
    cv_target = cv_df[cv_df["Target"] == target_name]

    # Box plot –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–æ–¥–µ–ª—ñ
    cv_data = []
    labels = []
    for model_name in ["Random Forest", "XGBoost", "LightGBM"]:
        model_cv = cv_target[cv_target["Model"] == model_name]
        if len(model_cv) > 0:
            fold_scores = model_cv[
                ["Fold 1", "Fold 2", "Fold 3", "Fold 4", "Fold 5"]
            ].values[0]
            cv_data.append(fold_scores)
            labels.append(model_name)

    if cv_data:
        bp = axes[idx].boxplot(cv_data, labels=labels, patch_artist=True)
        for patch in bp["boxes"]:
            patch.set_facecolor("lightblue")

        axes[idx].set_ylabel("Cross-Validation R¬≤")
        axes[idx].set_title(f"CV Scores: {target_name}")
        axes[idx].grid(True, alpha=0.3, axis="y")
        axes[idx].axhline(y=0.75, color="red", linestyle="--", label="Target (0.75)")
        axes[idx].legend()

plt.tight_layout()
plt.savefig(ML_DIR / "21_cv_scores_distribution.png", dpi=300, bbox_inches="tight")
plt.close()
print("  ‚úì Saved: 21_cv_scores_distribution.png")

print("\n‚úì –£—Å—ñ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ!")
print()


# ============================================================================
# 10. SUMMARY STATISTICS
# ============================================================================
print("=" * 80)
print("10. SUMMARY STATISTICS")
print("=" * 80)

print("\nBest Models per Target (by Test R¬≤):")
for target_name in ["overallScore", "timeToMarket", "communityGrowth"]:
    target_results = results_df[results_df["Target"] == target_name]
    best_model = target_results.loc[target_results["Test R¬≤"].idxmax()]

    print(f"\n  {target_name}:")
    print(f"    Best Model: {best_model['Model']}")
    print(f"    Test R¬≤: {best_model['Test R¬≤']:.4f}")
    print(f"    Test RMSE: {best_model['Test RMSE']:.4f}")
    print(f"    Test MAE: {best_model['Test MAE']:.4f}")

print("\n" + "=" * 80)
print("ML MODELING –ó–ê–í–ï–†–®–ï–ù–û!")
print("=" * 80)
print(f"\n–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ —Ñ–∞–π–ª–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: {ML_DIR}")
print("\nCSV Files:")
for csv_file in sorted(ML_DIR.glob("*.csv")):
    print(f"  ‚Ä¢ {csv_file.name}")

print("\nVisualizations:")
for png_file in sorted(ML_DIR.glob("*.png")):
    print(f"  ‚Ä¢ {png_file.name}")

print("\n‚úÖ –§–∞–∑–∞ 3: ML Modeling - SUCCESS!")
print()

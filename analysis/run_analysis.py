#!/usr/bin/env python3
"""
Data Validation & Exploration
–§–∞–∑–∞ 2.1: –í–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö —Ç–∞ exploratory data analysis

–ú–∞–≥—ñ—Å—Ç–µ—Ä—Å—å–∫–∞ —Ä–æ–±–æ—Ç–∞: Outcome-based –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ TypeScript –∫–æ–¥—É
–ê–≤—Ç–æ—Ä: –°–ª–∞–±–µ–Ω–∫–æ –ö–æ—Å—Ç—è–Ω—Ç–∏–Ω –û–ª–µ–≥–æ–≤–∏—á
–ì—Ä—É–ø–∞: –ê–°-202
–û–¥–µ—Å—å–∫–∏–π –ø–æ–ª—ñ—Ç–µ—Ö–Ω—ñ—á–Ω–∏–π –Ω–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç
"""

# –í–∏–º–∫–Ω—É—Ç–∏ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è
import warnings

# –Ü–º–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫
import json
from pathlib import Path

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
import matplotlib
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from pandas.plotting import scatter_matrix

warnings.filterwarnings("ignore")

matplotlib.use("Agg")  # –ë–µ–∑ GUI backend

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
plt.style.use("seaborn-v0_8-darkgrid")
sns.set_palette("husl")
plt.rcParams["figure.figsize"] = (12, 6)
plt.rcParams["font.size"] = 10

# –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
FIGURES_DIR = Path("../reports/analysis")
FIGURES_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 80)
print("–ü–û–ß–ê–¢–û–ö –ê–ù–ê–õ–Ü–ó–£ –î–ê–ù–ò–•")
print("=" * 80)

#  –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–•
print("\nüìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
with open("../reports/metrics_report.json", "r", encoding="utf-8") as f:
    data = json.load(f)

projects_data = data["projects"]
df = pd.DataFrame(projects_data)
print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df)} –ø—Ä–æ–µ–∫—Ç—ñ–≤")

# –†–û–ó–ì–û–†–¢–ê–ù–ù–Ø –ú–ï–¢–†–ò–ö
print("\nüîÑ –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è –≤–∫–ª–∞–¥–µ–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫...")
dx_df = pd.DataFrame(df["developerExperience"].tolist())
dx_df.columns = ["dx_" + col for col in dx_df.columns]

tp_df = pd.DataFrame(df["technicalPerformance"].tolist())
tp_df.columns = ["tp_" + col for col in tp_df.columns]

bi_df = pd.DataFrame(df["businessImpact"].tolist())
bi_df.columns = ["bi_" + col for col in bi_df.columns]

df_metrics = pd.concat(
    [df[["name", "overallScore", "confidence", "collectedAt"]], dx_df, tp_df, bi_df],
    axis=1,
)

numeric_cols = df_metrics.select_dtypes(include=[np.number]).columns.tolist()
print(
    f"‚úÖ –†–æ–∑–≥–æ—Ä–Ω—É—Ç–æ {len(df_metrics.columns)} –∫–æ–ª–æ–Ω–æ–∫, {len(numeric_cols)} —á–∏—Å–ª–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫"
)

# MISSING VALUES
print("\nüîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ missing values...")
missing_counts = df_metrics.isnull().sum()
total_cells = df_metrics.shape[0] * df_metrics.shape[1]
total_missing = missing_counts.sum()
completeness = (total_cells - total_missing) / total_cells * 100
print(f"‚úÖ Completeness: {completeness:.2f}%")

# –ö–ê–¢–ï–ì–û–†–Ü–á –ú–ï–¢–†–ò–ö
dx_cols = [col for col in numeric_cols if col.startswith("dx_")]
tp_cols = [col for col in numeric_cols if col.startswith("tp_")]
bi_cols = [col for col in numeric_cols if col.startswith("bi_")]

df_metrics["avg_dx"] = df_metrics[dx_cols].mean(axis=1)
df_metrics["avg_tp"] = df_metrics[tp_cols].mean(axis=1)
df_metrics["avg_bi"] = df_metrics[bi_cols].mean(axis=1)

# 1. OVERALL SCORE DISTRIBUTION
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 1/7: Overall Score Distribution...")
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

axes[0].hist(df_metrics["overallScore"], bins=15, edgecolor="black", alpha=0.7)
axes[0].axvline(
    df_metrics["overallScore"].mean(),
    color="red",
    linestyle="--",
    label=f"–°–µ—Ä–µ–¥–Ω—î: {df_metrics['overallScore'].mean():.2f}",
)
axes[0].axvline(
    df_metrics["overallScore"].median(),
    color="green",
    linestyle="--",
    label=f"–ú–µ–¥—ñ–∞–Ω–∞: {df_metrics['overallScore'].median():.2f}",
)
axes[0].set_xlabel("Overall Score")
axes[0].set_ylabel("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç—ñ–≤")
axes[0].set_title("–†–æ–∑–ø–æ–¥—ñ–ª –∑–∞–≥–∞–ª—å–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏ –ø—Ä–æ–µ–∫—Ç—ñ–≤")
axes[0].legend()
axes[0].grid(True, alpha=0.3)

axes[1].boxplot(df_metrics["overallScore"], vert=True)
axes[1].set_ylabel("Overall Score")
axes[1].set_title("Box Plot –∑–∞–≥–∞–ª—å–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏")
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(
    FIGURES_DIR / "01_overall_score_distribution.png", dpi=300, bbox_inches="tight"
)
plt.close()
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/01_overall_score_distribution.png")

# 2. CATEGORY SCORES BOXPLOT
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 2/7: Category Scores Boxplot...")
fig, ax = plt.subplots(figsize=(12, 6))

categories_data = [df_metrics["avg_dx"], df_metrics["avg_tp"], df_metrics["avg_bi"]]

bp = ax.boxplot(
    categories_data,
    labels=["Developer\nExperience", "Technical\nPerformance", "Business\nImpact"],
)
ax.set_ylabel("–°–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫")
ax.set_title("–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö")
ax.grid(True, alpha=0.3, axis="y")

means = [np.mean(d) for d in categories_data]
for i, mean in enumerate(means, 1):
    ax.plot(i, mean, "r*", markersize=15, label="–°–µ—Ä–µ–¥–Ω—î" if i == 1 else "")
    ax.text(
        i,
        mean + 2,
        f"{mean:.2f}",
        ha="center",
        va="bottom",
        fontsize=10,
        fontweight="bold",
    )

ax.legend()
plt.tight_layout()
plt.savefig(
    FIGURES_DIR / "02_category_scores_boxplot.png", dpi=300, bbox_inches="tight"
)
plt.close()
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/02_category_scores_boxplot.png")

# 3. CORRELATION MATRIX
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 3/7: Correlation Matrix...")
correlation_matrix = df_metrics[numeric_cols].corr()

fig, ax = plt.subplots(figsize=(16, 14))
sns.heatmap(
    correlation_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    center=0,
    square=True,
    linewidths=0.5,
    cbar_kws={"shrink": 0.8},
    ax=ax,
    annot_kws={"size": 6},
)
ax.set_title("–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫", fontsize=16, pad=20)
plt.tight_layout()
plt.savefig(FIGURES_DIR / "03_correlation_matrix.png", dpi=300, bbox_inches="tight")
plt.close()
correlation_matrix.to_csv(FIGURES_DIR / "correlation_matrix.csv")
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/03_correlation_matrix.png")

# OUTLIERS (IQR)
print("\nüîç –í–∏—è–≤–ª–µ–Ω–Ω—è outliers (IQR –º–µ—Ç–æ–¥)...")
iqr_outliers = []
for col in numeric_cols:
    Q1 = df_metrics[col].quantile(0.25)
    Q3 = df_metrics[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df_metrics[
        (df_metrics[col] < lower_bound) | (df_metrics[col] > upper_bound)
    ]

    if len(outliers) > 0:
        iqr_outliers.append({"–ú–µ—Ç—Ä–∏–∫–∞": col, "–ö—ñ–ª—å–∫—ñ—Å—Ç—å outliers": len(outliers)})

if len(iqr_outliers) > 0:
    iqr_df = pd.DataFrame(iqr_outliers)
    iqr_df.to_csv(FIGURES_DIR / "outliers_iqr.csv", index=False)
    print(f"‚ö†Ô∏è  –í–∏—è–≤–ª–µ–Ω–æ outliers —É {len(iqr_df)} –º–µ—Ç—Ä–∏–∫–∞—Ö")

    # 4. OUTLIERS VISUALIZATION
    print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 4/7: Outliers Detection...")
    top_outlier_metrics = (
        iqr_df.sort_values("–ö—ñ–ª—å–∫—ñ—Å—Ç—å outliers", ascending=False)["–ú–µ—Ç—Ä–∏–∫–∞"]
        .head(6)
        .tolist()
    )

    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()

    for i, col in enumerate(top_outlier_metrics):
        axes[i].boxplot(df_metrics[col].dropna(), vert=True)
        axes[i].set_ylabel("–ó–Ω–∞—á–µ–Ω–Ω—è")
        axes[i].set_title(col.replace("_", " ").title())
        axes[i].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "04_outliers_detection.png", dpi=300, bbox_inches="tight")
    plt.close()
    print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/04_outliers_detection.png")
else:
    print("‚úÖ Outliers –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ")

# 5. METRICS DISTRIBUTIONS
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 5/7: Metrics Distributions...")
key_metrics = [
    "overallScore",
    "dx_codeReviewDuration",
    "dx_prIterationRate",
    "tp_testCoverage",
    "tp_typeScriptErrorRate",
    "bi_activeContributors",
    "bi_communityGrowth",
    "bi_issueResolutionRate",
]

fig, axes = plt.subplots(4, 2, figsize=(16, 16))
axes = axes.flatten()

for i, metric in enumerate(key_metrics):
    if metric in df_metrics.columns:
        data = df_metrics[metric].dropna()

        axes[i].hist(data, bins=20, edgecolor="black", alpha=0.7)
        axes[i].axvline(
            data.mean(), color="red", linestyle="--", label=f"Œº={data.mean():.2f}"
        )
        axes[i].axvline(
            data.median(),
            color="green",
            linestyle="--",
            label=f"median={data.median():.2f}",
        )
        axes[i].set_xlabel(metric.replace("_", " ").title())
        axes[i].set_ylabel("–ß–∞—Å—Ç–æ—Ç–∞")
        axes[i].set_title(f"–†–æ–∑–ø–æ–¥—ñ–ª: {metric.replace('_', ' ')}")
        axes[i].legend()
        axes[i].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(FIGURES_DIR / "05_metrics_distributions.png", dpi=300, bbox_inches="tight")
plt.close()
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/05_metrics_distributions.png")

# 6. TOP/BOTTOM PROJECTS
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 6/7: Top/Bottom Projects...")
top_10 = df_metrics.nlargest(10, "overallScore")
bottom_10 = df_metrics.nsmallest(10, "overallScore")

fig, axes = plt.subplots(1, 2, figsize=(18, 8))

axes[0].barh(range(len(top_10)), top_10["overallScore"], color="green", alpha=0.7)
axes[0].set_yticks(range(len(top_10)))
axes[0].set_yticklabels([name.split("/")[-1] for name in top_10["name"]])
axes[0].set_xlabel("Overall Score")
axes[0].set_title("–¢–æ–ø-10 –ø—Ä–æ–µ–∫—Ç—ñ–≤ –∑–∞ Overall Score")
axes[0].invert_yaxis()
axes[0].grid(True, alpha=0.3, axis="x")

axes[1].barh(range(len(bottom_10)), bottom_10["overallScore"], color="red", alpha=0.7)
axes[1].set_yticks(range(len(bottom_10)))
axes[1].set_yticklabels([name.split("/")[-1] for name in bottom_10["name"]])
axes[1].set_xlabel("Overall Score")
axes[1].set_title("–ù–∞–π–Ω–∏–∂—á—ñ 10 –ø—Ä–æ–µ–∫—Ç—ñ–≤ –∑–∞ Overall Score")
axes[1].invert_yaxis()
axes[1].grid(True, alpha=0.3, axis="x")

plt.tight_layout()
plt.savefig(FIGURES_DIR / "06_top_bottom_projects.png", dpi=300, bbox_inches="tight")
plt.close()
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/06_top_bottom_projects.png")

# 7. SCATTER MATRIX
print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó 7/7: Scatter Matrix...")
scatter_metrics = [
    "overallScore",
    "avg_dx",
    "avg_tp",
    "avg_bi",
    "tp_testCoverage",
    "bi_communityGrowth",
]

fig = plt.figure(figsize=(16, 16))
scatter_matrix(
    df_metrics[scatter_metrics], alpha=0.7, figsize=(16, 16), diagonal="kde", grid=True
)
plt.suptitle("Scatter Matrix –∫–ª—é—á–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫", y=0.995, fontsize=16)
plt.tight_layout()
plt.savefig(FIGURES_DIR / "07_scatter_matrix.png", dpi=300, bbox_inches="tight")
plt.close()
print("‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ: reports/analysis/07_scatter_matrix.png")

# –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –î–ê–ù–ò–•
print("\nüíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤...")
df_metrics.to_csv("../reports/processed_metrics.csv", index=False)
df_metrics[numeric_cols].describe().to_csv(FIGURES_DIR / "descriptive_statistics.csv")

# –¢–û–ü –ö–û–†–ï–õ–Ø–¶–Ü–á
corr_pairs = []
for i in range(len(correlation_matrix.columns)):
    for j in range(i + 1, len(correlation_matrix.columns)):
        corr_pairs.append(
            {
                "–ú–µ—Ç—Ä–∏–∫–∞ 1": correlation_matrix.columns[i],
                "–ú–µ—Ç—Ä–∏–∫–∞ 2": correlation_matrix.columns[j],
                "–ö–æ—Ä–µ–ª—è—Ü—ñ—è": correlation_matrix.iloc[i, j],
            }
        )

corr_df = pd.DataFrame(corr_pairs)
corr_df = corr_df.sort_values("–ö–æ—Ä–µ–ª—è—Ü—ñ—è", key=abs, ascending=False)
corr_df.to_csv(FIGURES_DIR / "top_correlations.csv", index=False)

print("‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: reports/processed_metrics.csv")
print("‚úÖ –û–ø–∏—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞: reports/analysis/descriptive_statistics.csv")
print("‚úÖ –¢–æ–ø –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω—ñ: reports/analysis/top_correlations.csv")

# –í–ò–°–ù–û–í–ö–ò
print("\n" + "=" * 80)
print("–í–ò–°–ù–û–í–ö–ò")
print("=" * 80)
print(f"\n‚úÖ Completeness: {completeness:.2f}%")
print(f"‚úÖ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç—ñ–≤: {len(df_metrics)}")
print(f"‚úÖ –ö—ñ–ª—å–∫—ñ—Å—Ç—å –º–µ—Ç—Ä–∏–∫: {len(numeric_cols)}")
print(
    f"\nüìä Overall Score: Œº={df_metrics['overallScore'].mean():.2f}, œÉ={df_metrics['overallScore'].std():.2f}"
)
print(f"üìä Developer Experience: Œº={df_metrics['avg_dx'].mean():.2f}")
print(f"üìä Technical Performance: Œº={df_metrics['avg_tp'].mean():.2f}")
print(f"üìä Business Impact: Œº={df_metrics['avg_bi'].mean():.2f}")

if len(iqr_outliers) > 0:
    print(f"\n‚ö†Ô∏è  –í–∏—è–≤–ª–µ–Ω–æ outliers —É {len(iqr_outliers)} –º–µ—Ç—Ä–∏–∫–∞—Ö")
else:
    print("\n‚úÖ Outliers –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ")

top_corr = corr_df.iloc[0]
print(
    f"\nüîó –ù–∞–π—Å–∏–ª—å–Ω—ñ—à–∞ –∫–æ—Ä–µ–ª—è—Ü—ñ—è: {top_corr['–ú–µ—Ç—Ä–∏–∫–∞ 1']} ‚Üî {top_corr['–ú–µ—Ç—Ä–∏–∫–∞ 2']} (r={top_corr['–ö–æ—Ä–µ–ª—è—Ü—ñ—è']:.3f})"
)

print("\n‚úÖ –î–∞–Ω—ñ –≥–æ—Ç–æ–≤—ñ –¥–æ Feature Engineering —Ç–∞ ML –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è")
print("\n" + "=" * 80)
print("–ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û")
print("=" * 80)

# –°–ø–∏—Å–æ–∫ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
print("\nüìÅ –ó–ì–ï–ù–ï–†–û–í–ê–ù–Ü –§–ê–ô–õ–ò:")
print("reports/analysis/:")
for file in sorted(FIGURES_DIR.glob("*")):
    print(f"  ‚Ä¢ {file.name}")
print("reports/:")
print("  ‚Ä¢ processed_metrics.csv")

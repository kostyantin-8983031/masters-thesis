# Replication Package: Outcome-Based Code Quality Research

–¶–µ–π –¥–æ–∫—É–º–µ–Ω—Ç –º—ñ—Å—Ç–∏—Ç—å –ø–æ–≤–Ω–∏–π replication package –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è "–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ outcome-based –∞–Ω–∞–ª—ñ–∑—É TypeScript –∫–æ–¥—É".

**–î–ª—è –∫–æ–≥–æ:** –î–æ—Å–ª—ñ–¥–Ω–∏–∫–∏, peer reviewers, —Å—Ç—É–¥–µ–Ω—Ç–∏, —è–∫—ñ —Ö–æ—á—É—Ç—å –≤—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏ –∞–±–æ —Ä–æ–∑—à–∏—Ä–∏—Ç–∏ —Ü–µ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è.

---

## –ó–º—ñ—Å—Ç

1. [–û–≥–ª—è–¥ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è](#–æ–≥–ª—è–¥-–¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è)
2. [–°–∏—Å—Ç–µ–º–Ω—ñ –≤–∏–º–æ–≥–∏](#—Å–∏—Å—Ç–µ–º–Ω—ñ-–≤–∏–º–æ–≥–∏)
3. [–í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è](#–≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è)
4. [Dataset](#dataset)
5. [–í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫—Ä–æ–∫—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è](#–≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è-–∫—Ä–æ–∫—ñ–≤-–¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è)
6. [–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏](#–æ—á—ñ–∫—É–≤–∞–Ω—ñ-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)
7. [–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤](#–≤–∞–ª—ñ–¥–∞—Ü—ñ—è-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤)
8. [–†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è](#—Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è-–¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è)
9. [Troubleshooting](#troubleshooting)
10. [Citation](#citation)

---

## –û–≥–ª—è–¥ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è

### –ú–µ—Ç–∞

–î–æ—Å–ª—ñ–¥–∏—Ç–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ—é –º—ñ–∂ —Å—Ç–∞—Ç–∏—á–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ TypeScript –∫–æ–¥—É —Ç–∞ —Ä–µ–∞–ª—å–Ω–∏–º–∏ outcome —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤, —è–∫—ñ—Å—Ç—å –ø—Ä–æ–¥—É–∫—Ç—É, –±—ñ–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏) –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–Ω–∞–ª—ñ–∑—É –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö open source –ø—Ä–æ—î–∫—Ç—ñ–≤ –≤–µ–±-—Ä–æ–∑—Ä–æ–±–∫–∏.

### Research Questions

**RQ1:** –Ø–∫—ñ outcome-based –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞–π–±—ñ–ª—å—à strongly –∫–æ—Ä–µ–ª—é—é—Ç—å –∑ —è–∫—ñ—Å—Ç—é TypeScript –ø—Ä–æ–µ–∫—Ç—ñ–≤?

**RQ2:** –ß–∏ –º–æ–∂–Ω–∞ –ø–µ—Ä–µ–¥–±–∞—á–∏—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫ –∫–æ–¥—É?

**RQ3:** –Ø–∫—ñ –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –º–æ–∂–Ω–∞ –¥–∞—Ç–∏ –∫–æ–º–∞–Ω–¥–∞–º –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ –∫–æ–¥—É —Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ?

### –ú–µ—Ç–æ–¥–æ–ª–æ–≥—ñ—è

**–ü—ñ–¥—Ö—ñ–¥:** Quantitative empirical study

**Dataset:** 50 –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö TypeScript open-source –ø—Ä–æ–µ–∫—Ç—ñ–≤ (>5000 GitHub stars)

**–ú–µ—Ç—Ä–∏–∫–∏:** 20 outcome-based –º–µ—Ç—Ä–∏–∫ —É 3 –∫–∞—Ç–µ–≥–æ—Ä—ñ—è—Ö:

- Developer Experience (DX): 7 –º–µ—Ç—Ä–∏–∫
- Technical Performance (TP): 6 –º–µ—Ç—Ä–∏–∫
- Business Impact (BI): 7 –º–µ—Ç—Ä–∏–∫

**–ê–Ω–∞–ª—ñ–∑:**

- Phase 1: Data Collection (GitHub API, code analysis)
- Phase 2.1: Data Validation & Exploration (EDA)
- Phase 2.2: Statistical Analysis & Feature Engineering
- Phase 2.3: Temporal Data Collection & Analysis
- Phase 3: ML Modeling & Predictive Analysis

**–Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏:**

- Data collection: TypeScript, Node.js, Octokit (GitHub API)
- Analysis: Python, pandas, scikit-learn, matplotlib
- Statistical tests: Pearson correlation, OLS regression, ANOVA
- ML models: Linear Regression, Ridge, Lasso, ElasticNet, Random Forest, XGBoost, LightGBM

### –ö–ª—é—á–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

**Finding 1:** Code review duration –º–∞—î –Ω–∞–π—Å–∏–ª—å–Ω—ñ—à—É –∫–æ—Ä–µ–ª—è—Ü—ñ—é –∑ time to market (r = 0.881, p < 10‚Åª¬π‚Å∂)

**Finding 2:** Test coverage —î –≥–æ–ª–æ–≤–Ω–∏–º predictor –¥–ª—è community growth (83.4% feature importance)

**Finding 3:** Interaction effects –º—ñ–∂ DX —Ç–∞ TP —î –∫—Ä–∏—Ç–∏—á–Ω–∏–º–∏ (47.5% importance –¥–ª—è overallScore)

**Finding 4:** Linear models outperform complex models –Ω–∞ –º–∞–ª–æ–º—É dataset (n=50)

---

## –°–∏—Å—Ç–µ–º–Ω—ñ –≤–∏–º–æ–≥–∏

### Hardware

**–ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –≤–∏–º–æ–≥–∏:**

- CPU: 4 cores (Intel i5 or equivalent)
- RAM: 8 GB
- Disk: 10 GB free space
- Network: Stable internet (GitHub API calls)

**–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ñ –≤–∏–º–æ–≥–∏:**

- CPU: 8+ cores (Intel i7/AMD Ryzen 7 or better)
- RAM: 16 GB
- Disk: 20 GB free space (SSD preferred)
- Network: High-speed internet (rate limits)

### Software

**Required:**

- **Node.js:** 20.x –∞–±–æ –Ω–æ–≤—ñ—à–µ
- **npm:** 10.x –∞–±–æ –Ω–æ–≤—ñ—à–µ
- **Python:** 3.11+ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ 3.12)
- **Git:** 2.x –∞–±–æ –Ω–æ–≤—ñ—à–µ
- **GitHub Personal Access Token** (free tier –¥–æ—Å—Ç–∞—Ç–Ω—å–æ)

**Optional (recommended):**

- **uv:** Ultra-fast Python package installer
- **VS Code:** –î–ª—è –ø–µ—Ä–µ–≥–ª—è–¥—É –∫–æ–¥—É
- **Jupyter:** –î–ª—è interactive analysis

### Operating Systems

**Tested on:**

- ‚úÖ macOS 13+ (Ventura, Sonoma)
- ‚úÖ Ubuntu 22.04+ LTS
- ‚úÖ Windows 11 (—á–µ—Ä–µ–∑ WSL2)

**Note:** Windows native –Ω–µ —Ç–µ—Å—Ç—É–≤–∞–≤—Å—è, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ WSL2.

---

## –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

### Step 1: Clone Repository

```bash
# HTTPS
git clone https://github.com/konstantinkai/masters-thesis.git

# SSH (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
git clone git@github.com:konstantinkai/masters-thesis.git

cd masters-thesis
```

### Step 2: Install Node.js Dependencies

```bash
npm install
```

**Expected output:**

```
added 850 packages in 45s
```

**Verify:**

```bash
npm list --depth=0
# Should show @nx/*, @octokit/*, typescript, etc.
```

### Step 3: Install Python Dependencies

#### Option A: Using uv (recommended)

```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install packages
uv pip install pandas numpy scikit-learn matplotlib seaborn \
  scipy statsmodels xgboost lightgbm
```

#### Option B: Using pip

```bash
# Optional: Create virtual environment
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows

# Install packages
pip install pandas numpy scikit-learn matplotlib seaborn \
  scipy statsmodels xgboost lightgbm
```

**Verify:**

```bash
python3 -c "import pandas, sklearn, matplotlib; print('‚úÖ All packages installed')"
```

### Step 4: Setup GitHub Token

```bash
# Create .env file (NOT committed to git)
echo "GITHUB_TOKEN=your_github_token_here" > .env

# OR set environment variable
export GITHUB_TOKEN="your_github_token_here"

# Test connection
node packages/scripts/src/debug-github-api.mjs
```

**Expected output:**

```
‚úÖ GitHub API connection successful
Rate limit: 4999/5000 remaining
```

### Step 5: Build Project

```bash
# Build all TypeScript packages
npx nx run-many --target=build --all
```

**Expected output:**

```
‚úì Successfully ran target build for 3 projects
  - @thesis/metrics
  - @thesis/metrics-collector
  - @thesis/scripts
```

---

## Dataset

### Project Selection Criteria

**Inclusion criteria:**

- TypeScript > 70% codebase
- GitHub Stars > 5,000
- Open Issues > 50
- Pull Requests > 100 (last 6 months)
- Active development (>10 commits/month)
- Public repository
- CI/CD configured

**Exclusion criteria:**

- Archived repositories
- Private repositories
- Non-web projects (e.g., CLI tools without web output)
- Forks (only original repositories)

### Dataset Summary

**Total projects:** 50

**Categories:**

- Core TypeScript Projects: 10 (20%)
- UI Component Libraries: 10 (20%)
- State Management: 8 (16%)
- Build Tools: 6 (12%)
- Developer Tools: 8 (16%)
- Data & Forms: 8 (16%)

**Full project list:** See `input/projects.json`

**Example entry:**

```json
{
  "name": "Angular",
  "github": "angular/angular",
  "category": "Core Framework",
  "stars": 95000,
  "tier": 1
}
```

### Temporal Dataset (Phase 2.3)

**Time range:** April 2025 - September 2025 (6 months)

**Snapshots:** 300 total (50 projects √ó 6 snapshots)

**Interval:** Monthly (last day of each month)

**Data points:** 300 snapshots √ó 20 metrics = 6,000 data points

---

## –í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫—Ä–æ–∫—ñ–≤ –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è

### Phase 1: Data Collection

#### Step 1.1: Verify Projects Configuration

```bash
node packages/scripts/src/verify-projects.mjs
```

**Expected output:**

```
‚úÖ All 50 projects validated
‚úì angular/angular exists (95k stars)
‚úì facebook/react exists (220k stars)
...
```

**Estimated time:** 2-3 minutes

#### Step 1.2: Collect Metrics (Cross-Sectional)

```bash
node packages/scripts/src/detailed-metrics-report.mjs
```

**Expected output:**

```
üìä Starting metrics collection for 50 projects...

‚úì [1/50] Angular (angular/angular) - Score: 82/100 (3.2s)
‚úì [2/50] React (facebook/react) - Score: 79/100 (2.8s)
...

‚úÖ Collection complete!
   üìà Average score: 70.3/100
   ‚è±Ô∏è  Total time: 12m 34s
   üíæ Reports saved to: reports/
```

**Estimated time:** 10-15 minutes

**Output files:**

- `reports/metrics_report.json` (56KB)
- `reports/metrics_report.csv` (14KB)
- `reports/metrics_report.md` (9KB)

#### Step 1.3: Collect Temporal Data (Optional)

```bash
node packages/scripts/src/temporal-metrics-report.mjs
```

**Expected output:**

```
üìä Collecting temporal data (6 months)...

‚úì [1/50] Angular - 6 snapshots collected (45s)
‚ö†Ô∏è [49/50] Rate limit hit, waiting 60s...
‚úì [49/50] TypeORM - 6 snapshots collected (105s)
‚úì [50/50] Complete

‚úÖ Temporal collection complete!
   üìä Total snapshots: 300 (50 √ó 6)
   ‚è±Ô∏è  Total time: 75m
   üíæ Reports saved to: reports/
```

**Estimated time:** 60-90 minutes

**Output files:**

- `reports/metrics_report_temporal.json` (297KB)
- `reports/metrics_report_temporal_long.csv` (58KB)

### Phase 2.1: Data Validation & Exploration

#### Step 2.1.1: Data Validation

```bash
cd analysis
python3 data_validation.py
```

**Expected output:**

```
üìä Data Validation Report

Dataset summary:
  Projects: 50
  Metrics: 20
  Data points: 1000

Completeness:
  ‚úÖ Missing values: 0 (0.00%)
  ‚úÖ 100% completeness

Outliers (IQR method):
  13 metrics with outliers detected

Correlations:
  171 pairs tested
  Top correlation: bundleSize ‚Üî bundleLoadTime (r=1.000)

üìà Visualizations saved to: reports/analysis/
üìã Report saved to: reports/data_validation_report.md
```

**Estimated time:** 2-3 minutes

**Output files:**

- `reports/data_validation_report.md` (31 pages)
- `reports/analysis/01_overall_score_distribution.png`
- `reports/analysis/02_category_scores_boxplot.png`
- `reports/analysis/03_correlation_matrix.png`
- `reports/analysis/04_outliers_detection.png`
- `reports/analysis/05_metrics_distributions.png`
- `reports/analysis/06_top_bottom_projects.png`
- `reports/analysis/07_scatter_matrix.png`
- `reports/analysis/descriptive_statistics.csv`
- `reports/analysis/correlation_matrix.csv`
- `reports/analysis/top_correlations.csv`
- `reports/analysis/outliers_iqr.csv`

### Phase 2.2: Statistical Analysis

#### Step 2.2.1: Hypothesis Testing & Regression

```bash
python3 statistical_analysis.py
```

**Expected output:**

```
üìä Statistical Analysis Report

Hypothesis Testing:
  171 correlation pairs tested
  26 significant (p < 0.05): 15.2%
  14 significant after FDR: 8.2%

Regression Analysis:
  3 OLS models fitted
  Best R¬≤: 0.784 (timeToMarket ~ DX)

Cluster Analysis:
  Optimal clusters: k=2 (Silhouette=0.212)
  Cluster 0: 11 projects (22%)
  Cluster 1: 39 projects (78%)

PCA:
  10 components for 90% variance

üìà Visualizations saved to: reports/statistical/
üìã Report saved to: reports/statistical_analysis_report.md
```

**Estimated time:** 3-5 minutes

**Output files:**

- `reports/statistical_analysis_report.md` (40 pages)
- `reports/statistical/08_regression_analysis.png`
- `reports/statistical/09_optimal_clusters.png`
- `reports/statistical/10_hierarchical_dendrogram.png`
- `reports/statistical/11_pca_explained_variance.png`
- `reports/statistical/12_pca_biplot_clusters.png`
- `reports/statistical/hypothesis_tests.csv`
- `reports/statistical/regression_summary.csv`
- `reports/statistical/regression_coefficients.csv`
- `reports/statistical/cluster_assignments.csv`
- `reports/statistical/pca_loadings.csv`

#### Step 2.2.2: Feature Engineering

```bash
python3 feature_engineering.py
```

**Expected output:**

```
üìä Feature Engineering

Original features: 19
Interaction features: +5
Polynomial features: +5
Log transformations: +4
Ratio features: +4
Categorical features: +2
Scaled features: +80

Total engineered features: 126

Top feature: dx_codeReviewDuration_log (r=-0.582)

üíæ Saved to: reports/statistical/engineered_features.csv
```

**Estimated time:** 1-2 minutes

**Output files:**

- `reports/statistical/engineered_features.csv` (50 √ó 126)
- `reports/statistical/feature_importance.csv`

### Phase 2.3: Temporal Analysis (Optional)

#### Step 2.3.1: Time Series Analysis

```bash
python3 temporal_analysis.py
```

**Expected output:**

```
üìä Temporal Analysis Report

Dataset:
  Projects: 50
  Time range: 2025-04-01 to 2025-09-30
  Snapshots: 300 (6 per project)

Stationarity Tests (ADF):
  Stationary: 12/20 metrics (60%)
  Non-stationary: 8/20 metrics (40%)

Change Point Detection:
  Detected changes: 15 across 8 projects

Volatility:
  High volatility: dx_codeReviewDuration, bi_communityGrowth
  Low volatility: tp_testCoverage, tp_performanceScore

üìà Visualizations saved to: reports/temporal/
```

**Estimated time:** 5-7 minutes

**Output files:**

- `reports/temporal/01_metrics_trends_over_time.png`
- `reports/temporal/02_project_trajectories.png`
- `reports/temporal/03_seasonal_decomposition.png`
- `reports/temporal/04_acf_pacf_plots.png`
- `reports/temporal/05_change_point_detection.png`
- `reports/temporal/06_volatility_analysis.png`
- `reports/temporal/stationarity_tests.csv`
- `reports/temporal/change_points.csv`

#### Step 2.3.2: Temporal Feature Engineering

```bash
python3 temporal_feature_engineering.py
```

**Expected output:**

```
üìä Temporal Feature Engineering

Original features: 18
Lag features (1-3): +54
Rolling statistics: +135
Trend features: +18
Momentum features: +36
Volatility features: +36

Total temporal features: 297
Total features (with original): 315

üíæ Saved to: reports/temporal/temporal_features.csv
```

**Estimated time:** 3-5 minutes

**Output files:**

- `reports/temporal/temporal_features.csv` (300 √ó 315)

#### Step 2.3.3: Temporal Modeling

```bash
python3 temporal_modeling.py
```

**Expected output:**

```
üìä Temporal Modeling Report

ARIMA Forecasting:
  dx_codeReviewDuration: MAE=8.12%, RMSE=14.28%
  bi_timeToMarket: MAE=9.87%, RMSE=13.45%
  bi_communityGrowth: MAE=11.23%, RMSE=15.67%

Random Forest (TimeSeriesSplit CV):
  bi_timeToMarket: R¬≤=0.782, RMSE=9.96
  bi_communityGrowth: R¬≤=0.928, RMSE=6.66

Top predictors:
  timeToMarket: rolling_2m_max (0.357)
  communityGrowth: rolling_3m_mean (0.176)

üìã Report saved to: reports/temporal_implementation_summary.md
```

**Estimated time:** 10-15 minutes

**Output files:**

- `reports/temporal_implementation_summary.md` (15 sections)
- `reports/temporal/arima_forecasts.csv`
- `reports/temporal/rf_cv_results.csv`
- `reports/temporal/feature_importance_temporal.csv`

### Phase 3: ML Modeling

#### Step 3.1: Data Preparation

```bash
cd ../analysis  # if still in analysis/
python3 ml_data_preparation.py
```

**Expected output:**

```
üìä ML Data Preparation

Input features: 126
After correlation filter (r>0.95): 45
After data leakage removal: 24

Train/Val/Test split:
  Train: 34 projects (70%)
  Val: 8 projects (15%)
  Test: 8 projects (15%)

üíæ Saved to: reports/ml/selected_features.csv
```

**Estimated time:** 1-2 minutes

**Output files:**

- `reports/ml/selected_features.csv` (24 features)
- `reports/ml/train_test_split.csv`

#### Step 3.2: Model Training

```bash
python3 ml_modeling.py
```

**Expected output:**

```
üìä ML Modeling

Training 7 models √ó 3 targets = 21 model-target pairs

Models:
  ‚úì Linear Regression
  ‚úì Ridge Regression
  ‚úì Lasso Regression
  ‚úì ElasticNet
  ‚úì Random Forest
  ‚úì XGBoost
  ‚úì LightGBM

Targets:
  - overallScore
  - timeToMarket
  - communityGrowth

Best Test R¬≤:
  overallScore: 0.625 (Linear Regression)
  timeToMarket: 0.663 (Lasso)
  communityGrowth: 0.394 (Lasso)

üíæ Saved to: reports/ml/model_performance.csv
```

**Estimated time:** 5-10 minutes

**Output files:**

- `reports/ml/model_performance.csv` (21 rows)
- `reports/ml/cv_scores.csv`
- `reports/ml/models/` (saved model files)

#### Step 3.3: Model Evaluation

```bash
python3 ml_evaluation.py
```

**Expected output:**

```
üìä ML Evaluation

Feature Importance (XGBoost):
  overallScore: dx_tp_interaction (47.5%)
  timeToMarket: dx_codeReviewDuration (40.5%)
  communityGrowth: tp_testCoverage (83.4%)

SHAP Values:
  overallScore: dx_tp_interaction (2.517)
  timeToMarket: dx_codeReviewDuration (5.451)
  communityGrowth: tp_testCoverage (14.280)

üìà Visualizations saved to: reports/ml/
```

**Estimated time:** 5-7 minutes

**Output files:**

- `reports/ml/13_feature_selection.png`
- `reports/ml/14_model_comparison.png`
- `reports/ml/15_learning_curves.png`
- `reports/ml/16_residual_plots.png`
- `reports/ml/17_feature_importance_comparison.png`
- `reports/ml/18_predictions_vs_actual.png`
- `reports/ml/19_shap_summary.png`
- `reports/ml/20_shap_dependence_*.png` (3 files)
- `reports/ml/21_cv_scores_distribution.png`
- `reports/ml/feature_importance_rf_*.csv` (3 files)
- `reports/ml/feature_importance_xgb_*.csv` (3 files)
- `reports/ml/shap_importance_*.csv` (3 files)

#### Step 3.4: Generate Report

```bash
python3 ml_explainability.py
```

**Expected output:**

```
üìä ML Explainability Report

Generated comprehensive report:
  - Executive summary
  - Model performance comparison
  - Feature importance analysis
  - SHAP value interpretation
  - Practical recommendations
  - Limitations discussion

üìã Report saved to: reports/ml_modeling_report.md (50 pages)
```

**Estimated time:** 2-3 minutes

**Output files:**

- `reports/ml_modeling_report.md` (50 pages)
- `reports/ml/predictions_comparison.csv`

---

## –û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

### Summary Statistics

**Dataset:**

- Projects: 50
- Data points: 1,000 (50 √ó 20)
- Completeness: 100% (0 missing)
- Confidence: 90% –¥–ª—è –≤—Å—ñ—Ö

**Overall Score:**

- Mean: 70.3/100
- Median: 70.5/100
- Std: 6.4
- Range: 57-85/100

**Top 3 Projects:**

1. pmndrs/valtio - 85/100
2. nestjs/nest - 84/100
3. reduxjs/redux - 84/100

### Key Findings

**Finding 1: Code Review Critical**

```
codeReviewDuration ‚Üî timeToMarket
r = 0.881, p < 10‚Åª¬π‚Å∂
1 hour review ‚Üí 1.3 hours delivery delay
```

**Finding 2: Test Coverage Drives Community**

```
testCoverage ‚Üî communityGrowth
r = 0.772, p < 10‚Åª¬π‚Å∞
+10% coverage ‚Üí +70 stars/month
```

**Finding 3: Interaction Effects**

```
dx_tp_interaction ‚Üí overallScore
47.5% feature importance (XGBoost)
Balance DX and TP investments (50/50)
```

### ML Model Performance

**Best Models (Test Set):**

**overallScore:**

- Model: Linear Regression
- R¬≤: 0.625
- RMSE: 5.116 points
- MAE: 3.836 points

**timeToMarket:**

- Model: Lasso
- R¬≤: 0.663
- RMSE: 7.835 hours
- MAE: 6.016 hours

**communityGrowth:**

- Model: Lasso
- R¬≤: 0.394
- RMSE: 8.231 stars/month
- MAE: 6.233 stars/month

### Temporal Analysis (if completed)

**ARIMA Forecasting:**

- dx_codeReviewDuration: MAE = 8.12%
- bi_timeToMarket: MAE = 9.87%
- bi_communityGrowth: MAE = 11.23%

**Random Forest CV:**

- bi_timeToMarket: R¬≤ = 0.782
- bi_communityGrowth: R¬≤ = 0.928

---

## –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

### Automatic Validation

Run validation script:

```bash
python3 validate_results.py
```

**Expected checks:**

- ‚úÖ All output files exist
- ‚úÖ CSV files have correct number of rows/columns
- ‚úÖ JSON files are well-formed
- ‚úÖ R¬≤ values within expected range (0.0-1.0)
- ‚úÖ Correlation values within [-1, 1]
- ‚úÖ No NaN/Inf values in outputs

### Manual Validation

**Step 1: Check completeness**

```bash
ls -lh reports/metrics_report.json
# Should be ~56KB

ls -lh reports/ml_modeling_report.md
# Should be ~60KB (50 pages)
```

**Step 2: Verify key statistics**

```python
import pandas as pd

df = pd.read_csv('reports/metrics_report.csv')
print(f"Projects: {len(df)}")  # Should be 50
print(f"Mean score: {df['overallScore'].mean():.1f}")  # Should be ~70.3
print(f"Missing values: {df.isnull().sum().sum()}")  # Should be 0
```

**Step 3: Check correlations**

```python
corr_df = pd.read_csv('reports/analysis/correlation_matrix.csv', index_col=0)
print(corr_df.loc['dx_codeReviewDuration', 'bi_timeToMarket'])
# Should be ~0.88
```

**Step 4: Verify model performance**

```python
perf_df = pd.read_csv('reports/ml/model_performance.csv')
best = perf_df.loc[perf_df['target'] == 'overallScore', 'test_r2'].max()
print(f"Best R¬≤ for overallScore: {best:.3f}")
# Should be ~0.625
```

### Statistical Validation

**Shapiro-Wilk Test (normality):**

```python
from scipy import stats

df = pd.read_csv('reports/metrics_report.csv')
stat, p = stats.shapiro(df['overallScore'])
print(f"Shapiro-Wilk p-value: {p:.4f}")
# p > 0.05 ‚Üí normally distributed
```

**Pearson Correlation (code review ‚Üî time to market):**

```python
r, p = stats.pearsonr(df['dx_codeReviewDuration'], df['bi_timeToMarket'])
print(f"r = {r:.3f}, p = {p:.2e}")
# Should be r ‚âà 0.88, p < 0.001
```

---

## –†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è

### Extension 1: Expand Dataset

**Goal:** Increase to 150+ projects –¥–ª—è R¬≤ > 0.75

**Steps:**

1. Add projects to `input/projects.json`
2. Include 1000-5000 stars range (reduce selection bias)
3. Add non-TypeScript projects (JavaScript, Python) –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
4. Re-run data collection
5. Re-train models

**Expected improvement:**

- R¬≤ overallScore: 0.625 ‚Üí 0.75+
- Better generalization
- Lower CV variance

### Extension 2: Temporal Validation

**Goal:** Longitudinal study (12-24 months)

**Steps:**

1. Modify `temporal-metrics-report.mjs` –¥–ª—è extended range
2. Collect monthly snapshots (12-24 points per project)
3. ARIMA/Prophet forecasting
4. Validation: Train on past, predict future
5. Measure forecast accuracy

**Expected outcomes:**

- Causal inference (Granger causality)
- Seasonal patterns detection
- Better understanding of dynamics

### Extension 3: Qualitative Study

**Goal:** Developer survey –¥–ª—è validation

**Steps:**

1. Create survey (SPACE framework based)
2. Distribute to active contributors (GitHub issues)
3. Collect responses (target: 100+)
4. Correlate survey scores –∑ outcome metrics
5. Mixed-methods analysis

**Expected insights:**

- Validate quantitative findings
- Understand "why" (not just "what")
- Context-specific factors

### Extension 4: Real-World Tool

**Goal:** VS Code extension –¥–ª—è real-time quality scoring

**Steps:**

1. Design VS Code extension API
2. Implement lightweight metrics collector
3. Real-time scoring (local + GitHub API)
4. Display in status bar, notifications
5. Beta testing –∑ pilot teams

**Impact:**

- Actionable insights –¥–ª—è developers
- Continuous improvement tracking
- Industry adoption potential

---

## Troubleshooting

### Common Issues

#### Issue 1: GitHub Rate Limit

**Symptom:**

```
‚ö† [5/50] Rate limit hit, retrying in 60s...
```

**Solutions:**

1. Wait for automatic retry
2. Use `--existingReport` –¥–ª—è incremental updates
3. Schedule collection during off-peak hours
4. Upgrade to GitHub Pro (higher rate limits)

#### Issue 2: Python Import Errors

**Symptom:**

```
ModuleNotFoundError: No module named 'pandas'
```

**Solutions:**

```bash
# Option 1: uv
uv pip install pandas

# Option 2: pip
pip install pandas

# Option 3: Verify virtual environment
which python3
# Should point to venv/bin/python3 if using venv
```

#### Issue 3: Nx Build Failures

**Symptom:**

```
‚ùå Failed to build @thesis/metrics
```

**Solutions:**

```bash
# Clear cache
npx nx reset

# Clean install
rm -rf node_modules package-lock.json
npm install

# Rebuild
npx nx build @thesis/metrics
```

#### Issue 4: Incorrect Results

**Symptom:** Results differ –≤—ñ–¥ expected values

**Debug steps:**

1. Check dataset completeness:

   ```python
   df = pd.read_csv('reports/metrics_report.csv')
   print(df.shape)  # Should be (50, 23)
   print(df.isnull().sum())  # Should be all 0
   ```

2. Verify data collection date:

   ```bash
   grep "collectionDate" reports/metrics_report.json
   # Ensure it's recent
   ```

3. Re-run data collection:

   ```bash
   rm reports/metrics_report.*
   node packages/scripts/src/detailed-metrics-report.mjs
   ```

4. Check Python dependencies versions:
   ```bash
   pip list | grep -E "(pandas|scikit-learn|numpy)"
   # pandas ‚â• 2.0, scikit-learn ‚â• 1.3, numpy ‚â• 1.24
   ```

---

## Citation

–Ø–∫—â–æ –≤–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç–µ —Ü–µ–π dataset, –∫–æ–¥ –∞–±–æ results —É —Å–≤–æ—î–º—É –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—ñ, –±—É–¥—å –ª–∞—Å–∫–∞, cite:

### BibTeX

```bibtex
@mastersthesis{kai2025outcome,
  author = {Kai, Konstantin},
  title = {–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ outcome-based –∞–Ω–∞–ª—ñ–∑—É TypeScript –∫–æ–¥—É},
  school = {–û–¥–µ—Å—å–∫–∏–π –Ω–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π –ø–æ–ª—ñ—Ç–µ—Ö–Ω—ñ—á–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç},
  year = {2025},
  type = {Master's Thesis},
  address = {Odesa, Ukraine},
  note = {Speciality 121 - Software Engineering},
  url = {https://github.com/konstantinkai/masters-thesis}
}
```

### APA

```
Kai, K. (2025). –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ
outcome-based –∞–Ω–∞–ª—ñ–∑—É TypeScript –∫–æ–¥—É [Master's thesis, Odessa Polytechnic
National University]. GitHub. https://github.com/konstantinkai/masters-thesis
```

### IEEE

```
K. Kai, "–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ –Ω–∞ –æ—Å–Ω–æ–≤—ñ outcome-based
–∞–Ω–∞–ª—ñ–∑—É TypeScript –∫–æ–¥—É," Master's thesis, Odessa Polytechnic National University,
Odesa, Ukraine, 2025.
```

---

## –ö–æ–Ω—Ç–∞–∫—Ç–∏

**Author:** Konstantin Kai

**Affiliation:** Odessa Polytechnic National University (Speciality 121 - Software Engineering)

**Email:** konstantin.kai@example.com (update)

**GitHub:** [@konstantinkai](https://github.com/konstantinkai)

**Supervisor:** [–Ü–º'—è –Ω–∞—É–∫–æ–≤–æ–≥–æ –∫–µ—Ä—ñ–≤–Ω–∏–∫–∞] (update)

---

## –õ—ñ—Ü–µ–Ω–∑—ñ—è

–¶–µ–π replication package —Ä–æ–∑–ø–æ–≤—Å—é–¥–∂—É—î—Ç—å—Å—è –ø—ñ–¥ **MIT License**, —â–æ –¥–æ–∑–≤–æ–ª—è—î:

‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —É –∫–æ–º–µ—Ä—Ü—ñ–π–Ω–∏—Ö —Ç–∞ –∞–∫–∞–¥–µ–º—ñ—á–Ω–∏—Ö —Ü—ñ–ª—è—Ö
‚úÖ –ú–æ–¥–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ç–∞ —Ä–æ–∑–ø–æ–≤—Å—é–¥–∂–µ–Ω–Ω—è
‚úÖ –ü—Ä–∏–≤–∞—Ç–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

‚ö†Ô∏è –ó —É–º–æ–≤–æ—é –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è copyright notice —Ç–∞ attribution

**Full license text:** See `LICENSE` file –≤ repository root.

---

## –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–µ—Å—É—Ä—Å–∏

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

- [Architecture Guide](./architecture.md) - System design
- [Usage Guide](./usage_guide.md) - –î–µ—Ç–∞–ª—å–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
- [Best Practices Guide](./best_practices.md) - –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

### Reports

- [Data Validation Report](../reports/data_validation_report.md) - EDA (31 pages)
- [Statistical Analysis Report](../reports/statistical_analysis_report.md) - Statistics (40 pages)
- [ML Modeling Report](../reports/ml_modeling_report.md) - Machine Learning (50 pages)
- [Temporal Implementation](../reports/temporal_implementation_summary.md) - Time series (15 sections)

### External Resources

- **SPACE Framework:** https://queue.acm.org/detail.cfm?id=3454124
- **DORA Metrics:** https://dora.dev/
- **DevEx Framework:** https://queue.acm.org/detail.cfm?id=3595878
- **GitHub API:** https://docs.github.com/en/rest

---

**Document Version:** 1.0.0
**Last Updated:** November 13, 2025
**Status:** Phase 4 Implementation - Complete Replication Package

---

**Acknowledgments:**

Special thanks to:

- Open source maintainers –∑–∞ –ø—É–±–ª—ñ—á–Ω—ñ –¥–∞–Ω—ñ
- GitHub –∑–∞ API access
- Odessa Polytechnic National University –∑–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫—É
- Scientific supervisor –∑–∞ guidance
- Community –∑–∞ feedback

**Funding:** This research received no specific grant from any funding agency.

**Data Availability:** All data, code, and analysis scripts –¥–æ—Å—Ç—É–ø–Ω—ñ —É —Ü—å–æ–º—É repository.

**Ethics:** –¶e –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î only public data from open-source repositories. No personal identifying information –±—É–ª–æ –∑—ñ–±—Ä–∞–Ω–æ –∞–±–æ –æ–±—Ä–æ–±–ª complete–µ–Ω–æ. –í—Å—ñ –ø—Ä–∞–∫—Ç–∏–∫–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å GitHub Terms of Service —Ç–∞ GDPR regulations.
